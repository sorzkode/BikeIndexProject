{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Bike Index Project</h1>\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:black; color:white\">\n",
    "\n",
    "Author: **Mister Riley**  \n",
    "- GitHub: [https://github.com/sorzkode/](https://github.com/sorzkode/)\n",
    "- kaggle: [https://www.kaggle.com/code/misterriley/bikeindexeda](https://www.kaggle.com/code/misterriley/bikeindexeda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Extracting the data using the Bike Index API</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take approximately 30 minutes to run\n",
    "\n",
    "# Function to get bike data from the API\n",
    "def get_bike_data(api_key_name, api_key, page, per_page):\n",
    "    # API URL\n",
    "    api_url = \"https://bikeindex.org/api/v3/search\"\n",
    "    \n",
    "    # Include API key and key name in headers\n",
    "    headers = {\n",
    "        \"API-Key-Name\": api_key_name,\n",
    "        \"API-Key\": api_key\n",
    "    }\n",
    "\n",
    "    # Specify parameters for pagination\n",
    "    params = {\n",
    "        \"page\": page,\n",
    "        \"per_page\": per_page\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return the JSON response\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "# Function to save data to a JSON file\n",
    "def save_to_json(data):\n",
    "    file_path = os.path.join(\"SourceData\", \"bikedata.json\")\n",
    "\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load existing data from the file\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "    else:\n",
    "        existing_data = {\"bikes\": []}\n",
    "\n",
    "    # Append the new bike data to the existing list under \"bikes\"\n",
    "    existing_data[\"bikes\"].extend(data[\"bikes\"])\n",
    "\n",
    "    # Write the updated data back to the file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(existing_data, json_file, indent=2)  # Write the data to the JSON file with indentation\n",
    "        json_file.write('\\n')  # Add a new line after each JSON object\n",
    "\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    api_key_name = \"bearer\"\n",
    "    api_key = \"YOUR_API_KEY\"\n",
    "    per_page = 100\n",
    "\n",
    "    # Loop through the pages (1 to 500)\n",
    "    for page in range(1, 501):\n",
    "        # Get bike data for the current page\n",
    "        bike_data = get_bike_data(api_key_name, api_key, page, per_page)\n",
    "\n",
    "        if bike_data:\n",
    "            # Save the data to the combined JSON file\n",
    "            save_to_json(bike_data)\n",
    "\n",
    "# Check if the script is being run directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Call the main function to start the data extraction process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Loading JSON data into a list</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder path\n",
    "folder_path = \"SourceData\"\n",
    "\n",
    "# Get the list of JSON files in the folder\n",
    "json_files = [file for file in os.listdir(folder_path) if file.endswith(\".json\")]\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data_list = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for json_file in json_files:\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(folder_path, json_file)\n",
    "    \n",
    "    # Load JSON data\n",
    "    print(f\"Loading JSON data from {file_path}...\")\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Access the \"bikes\" key to get the list\n",
    "    bikes_list = data.get(\"bikes\", [])\n",
    "    \n",
    "    # Extend the data list with the bikes list\n",
    "    data_list.extend(bikes_list)\n",
    "\n",
    "print(\"JSON data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Converting the list into a dataframe</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data list to a DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "print(\"DataFrame created successfully!\")\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns into the dataframe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Exploring / transforming the data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # Display the column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Display the first 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date_stolen column to datetime format\n",
    "try:\n",
    "    df['date_stolen'] = pd.to_datetime(df['date_stolen'], errors='coerce', unit='s')\n",
    "    print(\"date_stolen column converted to datetime format successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while converting the date_stolen column: {str(e)}\")\n",
    "\n",
    "# Validate the conversion\n",
    "df['date_stolen'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = df['date_stolen'].min(skipna=True) # Get the earliest date\n",
    "latest_date = df['date_stolen'].max(skipna=True) # Get the latest date\n",
    "\n",
    "print(f\"Earliest date: {earliest_date}\") # Print the earliest date\n",
    "print(f\"Latest date: {latest_date}\") # Print the latest date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_stolen'] = pd.to_datetime(df['date_stolen']).dt.strftime('%B') # Extract the month from the date_stolen column\n",
    "df['month_stolen'].unique() # Validate the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the year column to datetime format\n",
    "try: \n",
    "    df['year'] = pd.to_datetime(df['year'], format='%Y').dt.year\n",
    "    print(\"year column converted to datetime format successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while converting the year column: {str(e)}\")\n",
    "\n",
    "# Validate the conversion\n",
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the year column has at least 1 invalid value (2029). \n",
    "df[df['year'] > 2024] # Check for more invalid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to correct the 'year' values\n",
    "def correct_year(year):\n",
    "    try:\n",
    "        # Convert to integer and check if greater than the current year\n",
    "        if int(year) > pd.Timestamp.now().year:\n",
    "            return str(int(year) - 100)\n",
    "        else:\n",
    "            return str(year)\n",
    "    except ValueError:\n",
    "        # Handle non-numeric values (e.g., if 'year' is already a string)\n",
    "        return year\n",
    "\n",
    "# Apply the correction function to the 'year' column\n",
    "df['year'] = df['year'].apply(correct_year)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df['year'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latitude and longitude into separate columns\n",
    "try:\n",
    "    df[['latitude', 'longitude']] = df['stolen_coordinates'].apply(lambda x: pd.Series(x) if x else pd.Series([None, None]))\n",
    "    print(\"Successfully split the 'stolen_coordinates' column into 'latitude' and 'longitude'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while splitting the 'stolen_coordinates' column: {str(e)}\")\n",
    "\n",
    "# Validate the split\n",
    "df[['latitude', 'longitude']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate missing values\n",
    "\n",
    "df['year'].fillna(2020, inplace=True)\n",
    "df['stolen_location'].fillna(\"Unknown\", inplace=True)\n",
    "df['date_stolen'].fillna(\"2020-01-01\", inplace=True)\n",
    "df['description'].fillna(\"Unknown\", inplace=True)\n",
    "df['frame_model'].fillna(\"Unknown\", inplace=True)\n",
    "df['stolen_coordinates'].fillna(\"Unknown\", inplace=True)\n",
    "df['latitude'].fillna(\"Unknown\", inplace=True)\n",
    "df['longitude'].fillna(\"Unknown\", inplace=True)\n",
    "df['month_stolen'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Use boolean indexing for 'location_found' based on 'status'\n",
    "if not 'stolen':\n",
    "    df['location_found'].fillna(df['stolen_location'])\n",
    "else:\n",
    "    df['location_found'].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Validate the interpolation\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['is_stock_img', 'large_img', 'external_id', 'registry_name', 'registry_url', 'thumb', 'url', 'propulsion_type_slug', 'cycle_type_slug', 'serial']\n",
    "\n",
    "try:\n",
    "    df.drop(columns=columns_to_drop, inplace=True) # Drop the columns from the DataFrame\n",
    "    print(\"Columns dropped successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while dropping columns: {str(e)}\")\n",
    "    \n",
    "# Validate the drop\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in categorical columns\n",
    "print(\"\\nUnique Values:\")\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object': \n",
    "        unique_values = df[column].astype('str').nunique() \n",
    "        print(f\"{column}: {unique_values} unique values\") # Check unique values in categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract colors into separate columns\n",
    "try:\n",
    "    df_colors = df['frame_colors'].apply(lambda x: pd.Series(x) if x else pd.Series([None]*len(x)))\n",
    "    # Rename columns to 'color1', 'color2', 'color3', etc.\n",
    "    df_colors.columns = [f'color{i+1}' for i in range(df_colors.shape[1])]\n",
    "    # Concatenate the new columns to the original DataFrame\n",
    "    df = pd.concat([df, df_colors], axis=1)\n",
    "    print(\"Successfully split the 'frame_colors' column\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while splitting the 'frame_colors' column: {str(e)}\")\n",
    "\n",
    "# Validate the split\n",
    "df[['color1','color2','color3']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop frame_colors column\n",
    "try:\n",
    "    df.drop(columns=['frame_colors'], inplace=True)\n",
    "    print(\"Successfully dropped the 'frame_colors' column.\")\n",
    "except Exception as e:      \n",
    "    print(f\"Error occurred while dropping the 'frame_colors' column: {str(e)}\")\n",
    "\n",
    "# Validate the drop\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in color columns\n",
    "print('color1 unique values:', df['color1'].unique())\n",
    "print('color2 unique values:', df['color2'].unique())\n",
    "print('color3 unique values:', df['color3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the color columns\n",
    "df['color1'] = df['color1'].replace('Silver, gray or bare metal', 'Silver')\n",
    "df['color2'] = df['color2'].replace('Silver, gray or bare metal', 'Silver')\n",
    "df['color3'] = df['color3'].replace('Silver, gray or bare metal', 'Silver')\n",
    "\n",
    "df['color1'] = df['color1'].replace('Stickers tape or other cover-up', 'Decals')\n",
    "df['color2'] = df['color2'].replace('Stickers tape or other cover-up', 'Decals')\n",
    "df['color3'] = df['color3'].replace('Stickers tape or other cover-up', 'Decals')\n",
    "\n",
    "# Filling missing values in color columns\n",
    "df[['color2', 'color3']] = df[['color2', 'color3']].fillna('None')\n",
    "\n",
    "# Validating the changes\n",
    "print('color1 unique values:', df['color1'].unique())\n",
    "print('color2 unique values:', df['color2'].unique())\n",
    "print('color3 unique values:', df['color3'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split manufacturer_name column\n",
    "try:\n",
    "    df[['manufacturer']] = df['manufacturer_name'].str.split(' ', expand=True)[[0]]\n",
    "    print(\"Successfully split the 'manufacturer_name' column.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred while splitting the 'manufacturer_name' column: {str(e)}\")\n",
    "\n",
    "# Validate the split\n",
    "df['manufacturer'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_columns = ['city', 'state', 'country']  # List of new column names\n",
    "split_values = df['stolen_location'].str.split(',', expand=True).fillna('')  # Split the stolen_location column and fill missing values with empty string\n",
    "\n",
    "for i, column in enumerate(location_columns):\n",
    "    df[column] = split_values[i].str.strip()  # Remove leading and trailing whitespaces\n",
    "\n",
    "df[location_columns].head(10)  # Validate the new columns\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_columns = ['state', 'zip']  # List of new column names\n",
    "split_state = df['state'].str.split(' ', expand=True).fillna('')  # Split the stolen_location column and fill missing values with empty string\n",
    "\n",
    "for i, column in enumerate(state_columns):\n",
    "    df[column] = split_state[i].str.strip()  # Remove leading and trailing whitespaces\n",
    "\n",
    "df[state_columns].head(10)  # Validate the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # Display descriptive statistics for the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Exporting data to perform some manual cleaning</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('SourceData/bikeindex.csv', index=False) # Save the cleaned data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Importing Cleaned Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path\n",
    "file_path = \"SourceData/bikeindex.csv\"\n",
    "\n",
    "# Import the CSV file into a dataframe with the correct encoding\n",
    "df_cleaned = pd.read_csv(file_path, encoding='latin1')\n",
    "\n",
    "# Display the dataframe\n",
    "df_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.info() # Display basic information about the dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.describe() # Display descriptive statistics for the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:green; color:white\">\n",
    "<h1>Visualizing Cleaned Data</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of stolen vs. not stolen bikes\n",
    "plt.figure(figsize=(8, 5)) # Set figure size\n",
    "df_cleaned['stolen'].value_counts().plot(kind='bar', color=['green', 'red']) # Plot count of stolen vs. not stolen bikes\n",
    "plt.title('Count of Stolen vs. Not Stolen Bikes')\n",
    "plt.xlabel('Stolen')\n",
    "plt.ylabel('Count')\n",
    "plt.show() # Display plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'year' column to integer\n",
    "df_cleaned['year'] = df_cleaned['year'].astype(float).astype(str)\n",
    "\n",
    "# Subtract 3350 from the count of 'year' 2020\n",
    "df_cleaned.loc[df_cleaned['year'] == 2020, 'year'] -= 3350\n",
    "\n",
    "# Plot histogram of the \"year\" column\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_years = df_cleaned['year'].value_counts().head(10)  # Get the top 10 most frequent years\n",
    "plt.bar(top_10_years.index, top_10_years.values, color='skyblue')\n",
    "plt.title('Frequency of Bike Thefts based on Model Year (Top 10)')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each month\n",
    "month_counts = df_cleaned[df_cleaned['month_stolen'] != 'Unknown']['month_stolen'].value_counts()\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "top_10_months = month_counts.head(10)  # Get the top 10 most frequent months\n",
    "top_10_months.plot(kind='bar', color='skyblue')\n",
    "plt.title('Frequency of Bike Thefts by Month (Top 10)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Thefts')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of bikes by manufacturer (top 10)\n",
    "top_10_manufacturers = df_cleaned['manufacturer'].value_counts().head(10)\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_manufacturers.plot(kind='bar', color='skyblue')\n",
    "plt.title('Frequency of Bike Thefts by Manufacturer (Top 10)')\n",
    "plt.xlabel('Manufacturer')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 colors\n",
    "top_10_colors = df_cleaned['color1'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 colors\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_colors.plot(kind='bar', color='skyblue')\n",
    "plt.title('Frequency of Bike Thefts by Color (Top 10)')\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['stolen_country'].unique() # Check unique values in 'stolen_country' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['stolen_country'] = df_cleaned['stolen_country'].replace({'CA': 'Canada', 'US': 'United States', 'IN': 'India', 'FR': 'France', 'ES': 'Spain', 'HU': 'Hungary', 'DE': 'Germany', 'GB': 'United Kingdom', 'AU': 'Australia', 'NL': 'Netherlands', 'PL': 'Poland', 'PT': 'Portugal', 'AT': 'Austria', 'RS': 'Serbia', 'CH': 'Switzerland', 'MX': 'Mexico', 'SG': 'Singapore', 'RO': 'Romania', 'DK': 'Denmark', 'CO': 'Columbia', 'BE': 'Belgium', 'PK': 'Pakistan', 'SK': 'Slovakia', 'IT': 'Italy', 'VN': 'Vietnam'}) # Replace country codes with country names\n",
    "\n",
    "df_cleaned['country'].unique() # Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['state'].head(10) # Display the 'state' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping US state abbreviations to their full names\n",
    "us_states_mapping = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}\n",
    "\n",
    "# Replace 'stolen_country' column values with full names using the dictionary\n",
    "df_cleaned['state'] = df_cleaned['state'].replace(us_states_mapping) \n",
    "df_cleaned['state'].head(50) # Validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned['city'].head(50) # Display the 'city' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove and interpolate missing values in 'city', 'state', and 'country' columns\n",
    "df_cleaned['city'] = df_cleaned['city'].str.replace('city of', '') # Remove 'city of' from 'city' column values\n",
    "df_cleaned['city'].fillna('Unknown', inplace=True) # Replace missing values with 'Unknown'\n",
    "df_cleaned['state'].fillna('Unknown', inplace=True) # Replace missing values with 'Unknown'\n",
    "df_cleaned['country'].fillna('Unknown', inplace=True) # Replace missing values with 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.loc[df_cleaned['city'] == 'US', 'country'] = 'United States' # Replace 'US' in 'country' column with 'United States'\n",
    "df_cleaned.head(10) # Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each country\n",
    "country_counts = df_cleaned[df_cleaned['country'] != '']['country'].value_counts()\n",
    "\n",
    "# Sort the countries in descending order\n",
    "sorted_countries = country_counts.sort_values(ascending=False)\n",
    "\n",
    "# Select the top 10 countries\n",
    "top_10_countries = sorted_countries.head(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_10_countries.plot(kind='bar', color='skyblue')\n",
    "plt.title('Top 10 Countries by Stolen Bikes')\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 states\n",
    "top_10_states = df_cleaned[(df_cleaned['country'] == 'United States') & (df_cleaned['state'] != '')]['state'].value_counts().head(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_states.plot(kind='bar', color='skyblue')\n",
    "plt.title('Top 10 States in the United States by Bike Thefts')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 10 cities\n",
    "top_10_cities = df_cleaned[\n",
    "    (df_cleaned['stolen_country'] == 'United States') \n",
    "    & \n",
    "    (df_cleaned['stolen_city'] != 'Unknown')]['stolen_city'].value_counts().head(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_cities.plot(kind='bar', color='skyblue')\n",
    "plt.title('Top 10 Cities in the United States by Bike Thefts')\n",
    "plt.xlabel('City')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 states with the least thefts\n",
    "bottom_10_states = df_cleaned[df_cleaned['stolen_country'] == 'United States']['stolen_state'].value_counts().tail(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bottom_10_states.plot(kind='bar', color='skyblue')\n",
    "plt.title('10 States with the Least Bike Thefts')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 10 cities with the least thefts\n",
    "bottom_10_cities = df_cleaned[df_cleaned['stolen_country'] == 'United States']['stolen_city'].value_counts().tail(10)\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bottom_10_cities.plot(kind='bar', color='skyblue')\n",
    "plt.title('10 Cities with the Least Bike Thefts')\n",
    "plt.xlabel('State')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new CSV file\n",
    "df_cleaned.to_csv('bikedata_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
